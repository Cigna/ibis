<action name="fake_mth_tablename_import">
    <sqoop xmlns="uri:oozie:sqoop-action:0.4">
        <configuration>
            <property>
                <name>fs.hdfs.impl.disable.cache</name>
                <value>true</value>
            </property>
        </configuration>
        <arg>import</arg>
        <arg>-D hadoop.security.credential.provider.path=jceks://hdfs/user/dev/fake.passwords.jceks</arg>
        <arg>--as-avrodatafile</arg>
        <arg>--verbose</arg>
        <arg>--connect</arg>
        <arg>jdbc:teradata://fake.teradata/DATABASE=fake_database</arg>
        <arg>--target-dir</arg>
        <arg>/user/data/ingest/mdm/member/fake_database/fake_mth_tablename</arg>
        <arg>--delete-target-dir</arg>
        <arg>--username</arg>
        <arg>fake_username</arg>
        <arg>--password-alias</arg>
        <arg>fake.password.alias</arg>
        <arg>-m</arg>
        <arg>6</arg>
        <arg>--driver</arg>
        <arg>com.teradata.jdbc.TeraDriver</arg>
        <arg>--split-by</arg>
        <arg>client_struc_key</arg>
        <arg>--query</arg>
        <arg>SELECT Col1, Col2, client_struc_key FROM FAKE_DATABASE.FAKE_MTH_TABLENAME WHERE 1=1  AND ${sql_query}  AND $CONDITIONS</arg>
        <arg>--map-column-java</arg>
        <arg>Col2=String</arg>
        <arg>--</arg>
        <arg>--batch-size</arg>
        <arg>50000</arg>
        <arg>--relaxed-isolation</arg>
        <arg>--input-method</arg>
        <arg>split.by.amp</arg>
        <arg>--access-lock</arg>
    </sqoop>
    <ok to="fake_mth_tablename_avro"/>
    <error to="kill"/>
</action>
